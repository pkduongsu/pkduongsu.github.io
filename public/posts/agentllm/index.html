<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Understanding LLM and AI Agents | Kim&#39;s Blog</title>
<meta name="keywords" content="Agents, LLM, transformers">
<meta name="description" content="In recent statements, NVIDIA CEO Jensen Huang declared that we are entering the era of “agentic AI” - a new generation of AI that can autonomously perform complex, multi-step tasks such as data analysis, decision-making, or even interacting with both digital and physical environments. These AI agents will not stop at being software tools only but are now envisioned to be a new digital workforce that will soon revolutionize industries.">
<meta name="author" content="Kim Duong Pham">
<link rel="canonical" href="http://localhost:1313/posts/agentllm/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/agentllm/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Kim&#39;s Blog (Alt + H)">Kim&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Understanding LLM and AI Agents
    </h1>
    <div class="post-meta"><span title='2025-03-18 07:33:53 +1100 AEDT'>March 18, 2025</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;Kim Duong Pham

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#agents" aria-label="Agents">Agents</a></li>
                <li>
                    <a href="#llm" aria-label="LLM">LLM</a><ul>
                        
                <li>
                    <a href="#transformer" aria-label="Transformer">Transformer</a></li>
                <li>
                    <a href="#attention-is-all-you-need" aria-label="Attention is all you need">Attention is all you need</a></li>
                <li>
                    <a href="#training-llm" aria-label="Training LLM">Training LLM</a></li>
                <li>
                    <a href="#getting-desired-responses-from-models" aria-label="Getting desired responses from models">Getting desired responses from models</a></li></ul>
                </li>
                <li>
                    <a href="#tools" aria-label="Tools">Tools</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a></li>
                <li>
                    <a href="#resources" aria-label="Resources">Resources</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In recent statements, NVIDIA CEO Jensen Huang declared that we are entering the era of “agentic AI” - a new generation of AI that can autonomously perform complex, multi-step tasks such as data analysis, decision-making, or even interacting with both digital and physical environments. These AI agents will not stop at being software tools only but are now envisioned to be a new digital workforce that will soon revolutionize industries.</p>
<p><img alt="Image1" loading="lazy" src="/images/image1.png">
<em>NVIDIA’s vision of AI development</em></p>
<p>While it is still a bit too soon to have AIs wash dishes and do laundry for me, it is absolutely fascinating how the reasoning capabilities of recent Large Language Models - LLM have evolved to simulate the process of reasoning, planning, and decision-making of humans with minimal human intervention. These recent advancements opened the capability of AIs to act like our collaborators, rather than just as tools similar to Google Search, which simply gives the information for us to act upon in the last 25 years or so.</p>
<p>The possibilities just seemed endless.</p>
<p>So, in a humble effort to jump on the hype train myself, this post summarizes what I have learned so far regarding the topic of AI Agents and LLMs, and I sincerely hope I will be able to extend my knowledge in this area even further in my future projects and writings.</p>
<h1 id="agents">Agents<a hidden class="anchor" aria-hidden="true" href="#agents">#</a></h1>
<p>The term “Agent” is not new and in fact, has been used in the concept of intelligent agents - a popular paradigm of artificial intelligence, offering a fundamental perspective to define and understand AI. In this case, intelligence is defined as the <strong>capability to reason, problem-solving, learn and adapt itself to changes, and perform complex tasks.</strong> <em>Artificial Intelligence: A Modern Approach</em> (1995) defines an agent as <strong>anything that perceives its environment through sensors and acts upon it using actuators.</strong></p>
<p>In other words, the agent is characterized by the environment it operates in and the set of actions it can perform. It was called agent because of agency, i.e the ability to interact with its environment.</p>
<p>The environment the agent operates in is defined by its use case. For a vacuum cleaner agent, the environment is the room it is supposed to clean. Or, for an agent developed to play a game (LOL, Dota, Go, Chess), the environment is the game itself.</p>
<p>On the other hand, the scope of possible actions that the agent can take depends on the tools it has access to. ChatGPT is essentially an agent with access to tools like web search, image generation, and code execution.</p>
<p>There’s <strong>a</strong> <strong>strong dependency between an agent’s environment and its set of tools</strong>. The environment determines what tools an agent can potentially use, while an agent’s toolkit restricts the environment it can operate. For example, for an agent that plays chess, the only possible actions for the agent are valid chess moves, while the environment available for that agent to operate in is restricted in the chess board.</p>
<p>An AI agent is supposed to complete tasks typically defined by users. In an AI Agent, the <strong>Brain</strong> (which is now powered by powerful LLMs) is responsible for handling reasoning, and planning, and decides which action to take based on the situation, while the <strong>Body</strong> represents everything that the Agent was equipped to work with (capabilities and tools). Since the agent’s possible Actions depend on what the Agent has in hand to work with, <strong>the design of tools is crucial and has a great impact on the quality and success of the Agent.</strong></p>
<p>There are several types of AI models for AI Agents, with the most common being <strong>Large Language Models (LLM)</strong>, which excel at understanding and generating human language. However, it is also possible to implement models that accept other formats of input, such as <strong>Vision Language Models (VLM)</strong>, which empower the agent with visual capabilities, enabling them to solve more real-world challenges, such as web browsing or document understanding, tasks that require analyzing rich visual content.</p>
<p>Empowering Agents with capabilities to interact with their environment allows real-life usage for companies and individuals. Example use cases can include personal virtual assistants (Siri, Alexa), customer service chatbots, or AI NPCs in games.</p>
<p>💡In summary, <strong>AI Agents are AI models capable of reasoning, planning, and interacting with their environments</strong>. Agents perform <strong>Tasks</strong> implemented via <strong>Tools</strong> to complete defined <strong>Actions.</strong></p>
<h1 id="llm">LLM<a hidden class="anchor" aria-hidden="true" href="#llm">#</a></h1>
<p>But what exactly is a Large Language Model, and how can this power AI Agents to extract necessary information, reason, and learn?</p>
<p>In order to understand this, we start with the basic unit of Language Models: <strong>tokens</strong>, which can be a character, a word, or a sub-part of a word (-tion, -ing for example). For each model, developers decide how the original text can be broken down into tokens, therefore forming the set of tokens that the model can work with (or, a model’s <strong>vocabulary</strong>). This process is called <strong>tokenization</strong>.</p>
<p>Tokenization allows breaking words into meaningful content while reducing the size of the model’s vocabulary for efficiency. English vocabulary contains around 600,000 words, but LLM, in this case, Llama2, has a vocabulary of around 32,000 words only, as sub-words can be combined and reused (do-ing, work-ing for instance).</p>
<p><img alt="Image2" loading="lazy" src="/images/image2.png">
<em>How GPT tokenizes a phrase (Source: AI Engineering - Chip Huyen)</em></p>
<p><strong>By definition, A language model contains statistical information about 1 or more languages, with the objective of predicting the next token, given a sequence of previous tokens.</strong></p>
<p>There are <strong>two main types of language models</strong>:</p>
<ul>
<li>
<p><strong>Autoregressive (or causal language models):</strong> predict the next token <strong>using only preceding tokens.</strong> This allows models to generate tokens one after another, therefore making this model type ideal for text-generation tasks.</p>
</li>
<li>
<p><strong>Masked:</strong> predict missing <strong>tokens using context before/after the missing token.</strong> (BERT for example). This model type is ideal for non-generative tasks, such as sentiment analysis, and text classification, or tasks that require an understanding of context such as debugging.</p>
</li>
</ul>
<p>We can think of a language model as a completion machine, which tries to complete the text with the given prompt. Since the completion of models is essentially predictions based on probabilities, it is not guaranteed to be correct. However, there are infinite possible outputs to be constructed from the model’s finite vocabulary.</p>
<p>A model that generates open-ended out is called a generative model, in other words, <strong>generative AI.</strong></p>
<p>The <strong>model size</strong> is measured by the number of parameters, with parameters being variables within a Machine Learning model updated through the training process. Generally, more parameters result in a greater capacity for learning desired behaviors, and therefore, larger models have a greater capacity to learn and reason, which in turn requires more training data to maximize performance.</p>
<h2 id="transformer">Transformer<a hidden class="anchor" aria-hidden="true" href="#transformer">#</a></h2>
<p>Most models are built on the <strong>Transformer</strong> architecture:</p>
<p><img alt="Image3" loading="lazy" src="/images/image3.png">
<em>Transformer architecture</em></p>
<p>There are 3 types of transformers:</p>
<ul>
<li>
<p><strong>Encoder:</strong> takes text or other data as input and outputs a dense representation (embedding) of that text.</p>
<ul>
<li>
<p>Ex: BERT</p>
</li>
<li>
<p>Use case: Text Classification, semantic search, Named Entity Recognition (NER).</p>
</li>
<li>
<p>Size: Millions of parameters.</p>
</li>
</ul>
</li>
<li>
<p><strong>Decoders:</strong> focuses on generating new tokens to complete a sequence, one token at a time.</p>
<ul>
<li>
<p>Ex: Meta Llama.</p>
</li>
<li>
<p>Use case: text generation, chatbots, code generation</p>
</li>
<li>
<p>Size: Billions of parameters.</p>
</li>
</ul>
</li>
<li>
<p><strong>Seq2Seq (Encoder-Decoder):</strong> combines encoder and decoder. The encoder first processes the input sequence into context representation, and the decoder generates an output sequence.</p>
<ul>
<li>
<p>Ex: T5, BART</p>
</li>
<li>
<p>Use Cases: Translation, Summarization, Paraphrasing</p>
</li>
<li>
<p>Size: Millions of parameters.</p>
</li>
</ul>
</li>
</ul>
<p><strong>LLM are typically decoder-based models with billions of parameters,</strong> with examples being DeepSeekR1, GPT-4, and Llama3.</p>
<p><strong>Each LLM has some special tokens specific to the model that they use to open and close the structured components of its generation (indicate start, end of sequence, message, response).</strong></p>
<p>As mentioned before, LLM is <strong>autoregressive</strong>, meaning the output from one pass becomes the input for the next one, and this <strong>continues until the model predicts the next token to be an EOS token</strong>, and the model will stop. (LLM decode until EOS - end of sequence).</p>
<p>In a decoding loop:</p>
<ul>
<li>
<p>Input text is tokenized → model computes a representation of the sequence that captures information about the meaning and position of each token in the input sequence.</p>
</li>
<li>
<p>This goes into the model, which outputs scores that rank the probability (likelihood) of each token in the model’s vocab as being the next one in the sequence.</p>
</li>
<li>
<p>Based on this score → strategies to select the tokens to complete the sentence.</p>
</li>
</ul>
<p>The easiest decoding strategy would be to always take the token with the max score, but there are other advanced decoding strategies, such as Beam Search: exploring multiple candidate sequences to find the one with the maximum total score, even if some individual tokens have lower scores.</p>
<h2 id="attention-is-all-you-need"><strong>Attention is all you need</strong><a hidden class="anchor" aria-hidden="true" href="#attention-is-all-you-need">#</a></h2>
<p>A key aspect of transformer architecture is the <strong>Attention</strong> mechanism: when the model is predicting the next word, <strong>not all words are equally important.</strong></p>
<p>💡For example, given this input sentence: The Capital of France is….</p>
<p>“capital” and “France” carry the most meaning!</p>
<p>While the basic principle of LLM - predicting the next token - has remained constant since the release of GPT 2, there have been significant advancements in scaling neural networks and making attention mechanisms work for longer and longer sequences. (as in, improving context length - maximum no of tokens LLM can process, and the maximum attention span it has).</p>
<p>(It kinda sucks how AI’s attention span is growing while human’s shrinks LOL.)</p>
<h2 id="training-llm">Training LLM<a hidden class="anchor" aria-hidden="true" href="#training-llm">#</a></h2>
<p>A fundamental problem with the traditional learning method in supervised learning - training with only labeled data and apply to new data once trained - is that it was very expensive and slow to obtain data. Instead, language models can be trained using self-supervision, where:</p>
<ul>
<li>
<p>Model infer labels from input data instead of requiring explicit labels.</p>
</li>
<li>
<p>Each input sequence provides both the labels (tokens to be predicted) and the context model can be used to predict the labels.</p>
</li>
<li>
<p>This means models can learn from text sequences without any labeling, because text sequences are everywhere around us.</p>
</li>
</ul>
<p><img alt="Image4" loading="lazy" src="/images/image4.png">
<em>Example of self-supervision training labels</em></p>
<h2 id="getting-desired-responses-from-models">Getting desired responses from models<a hidden class="anchor" aria-hidden="true" href="#getting-desired-responses-from-models">#</a></h2>
<p>There are different approaches to get the desired responses from models:</p>
<ul>
<li>
<p><strong>Prompt engineering:</strong> craft detailed instructions + examples of the desirable product descriptions. <strong>Considering LLM’s job is to predict the next token by looking at every input token, and to choose which are important, the wording of your input sequence is very important to get the desired responses.</strong></p>
</li>
<li>
<p><strong>Retrieval-augmented generation (RAG):</strong> using a database to supplement the instructions.</p>
</li>
<li>
<p><strong>Fine-tune:</strong> further train the model on a dataset of high-quality product descriptions to perform specific tasks in desired domains.</p>
</li>
</ul>
<p>Each approach has different layers of concepts and applications that we need to understand to implement effectively, and since this post is already long, I will not go into details but will conduct more research and mention in other blog posts of mine along with my learning journey.</p>
<h1 id="tools">Tools<a hidden class="anchor" aria-hidden="true" href="#tools">#</a></h1>
<p>Tools help agents both to perceive and to act upon the surrounding environment. In the context of having LLM as the agent’s brain, <strong>a tool is a function given to the LLM to fulfill a defined objective.</strong></p>
<p>Common tools used for AI agents (that you may have seen from using various models) include web search, image generation, retrieval, or external API interfaces. These are just some of the common examples, you can create a tool for any use case desired.</p>
<p><strong>A good tool should be able to complement the power of an LLM.</strong> For example, LLMs generate outputs based on their training data only. If we want the model to generate up-to-date data, we need to give the model the capability to access and retrieve it, i.e web search tools.</p>
<p><strong>A tool should contain:</strong></p>
<ul>
<li>
<p>A textual description of what the function does.</p>
</li>
<li>
<p>a <strong>Callable</strong> (something to perform an action).</p>
</li>
<li>
<p><strong>Arguments</strong> with typings.</p>
</li>
<li>
<p><strong>(Optional): Outputs</strong> with typings.</p>
</li>
</ul>
<p>For the model to use the tool, we need to teach the LLM about the existence of tools and ask the model to generate text that will invoke tools when it needs to. We have to be concise and accurate about <strong>what the tool does</strong>, and what <strong>exact inputs it expects.</strong> Therefore, tool descriptions are usually provided using expressive but precise structures, such as computer languages or JSON.</p>
<p><strong>We give tools to a LLM through the system prompt, providing textual descriptions of available tools to the model.</strong></p>
<p>The Agent has the responsibility to parse LLM’s output, recognize that a tool call is required, and invoke the tool on LLM’s behalf. The output from the tool will then be sent back to the LLM, which will compose its final response for the user.</p>
<p>Example of a calculator tool that multiplies 2 integers:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculator</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Multiply two integers.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">*</span> b
</span></span></code></pre></div><p>With this tool, the description for the LLM to understand will be the following:Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: int</p>
<p>If we want to provide additional tools, we must be consistent and always use the same format, which can be fragile, and we can often overlook details.</p>
<p>⇒ Auto-formatting tool sections → leverage the source code and build a tool description automatically.</p>
<p>Build a Tool class for reusability whenever we use a tool, that has:</p>
<ul>
<li>
<p>Attributes: name of the tool, textual description, function (callable) of the tool, arguments list, outputs.</p>
</li>
<li>
<p>A function to return the string representation of the tool in a defined format.</p>
</li>
<li>
<p>Function to invoke the underlying callable with provided arguments.</p>
</li>
<li>
<p>We use Python’s Inspect module to retrieve all information for us (@tool decorator).</p>
</li>
</ul>
<p>→ use tool’s to_string method to retrieve text suitable to be used as a tool description for LLM → description then is injected in the system prompt.</p>
<p>An example of how a tool is created in <strong>smolagents framework,</strong> using the @tool decorator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">@tool</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calculator</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Multiply two integers.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">*</span> b
</span></span></code></pre></div><h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>At the core, the concept of Agent is fairly simple and has been around in the context of engineering and Artificial Intelligence even before the birth of modern Large Language Models. However, such models now can act as the agents’ brains for reasoning and planning, and are given access to tools and environmental feedback to find the best ways to complete tasks. Tools make agents vastly more capable, so the agentic pattern emerges naturally.</p>
<p>This post has covered the concept of Agents, Language Models, and Tools for Agents. However, there are so many more topics to cover regarding the world of Agent Systems, such as designing multiagent systems, planning approaches (ReAct approach for example), memory systems to enhance models’ context handling capabilities, RAG agents, and leveraging new frameworks to build functional agent systems, etc.., in which I am still in the process of learning and implementing those myself.</p>
<p>So, I’ll explore how those key concept works in future blog posts and try my best to stay consistent in this journey.</p>
<h1 id="resources">Resources<a hidden class="anchor" aria-hidden="true" href="#resources">#</a></h1>
<p>Below are some learning/reading resources that I have read and cited from to write this blog:</p>
<p><a href="https://www.oreilly.com/library/view/ai-engineering/9781098166298/">AI Engineering - Chip Huyen</a></p>
<p><a href="https://github.com/yanshengjia/ml-road/raw/master/resources/Artificial%20Intelligence%20-%20A%20Modern%20Approach%20(3rd%20Edition).pdf">Artificial Intelligence: A Modern Approach</a></p>
<p><a href="https://huggingface.co/learn/agents-course/unit0/introduction">Huggingface Agents Course</a></p>
<p><a href="https://huyenchip.com/2025/01/07/agents.html">https://huyenchip.com/2025/01/07/agents.html</a></p>
<p><a href="https://lilianweng.github.io/posts/2023-06-23-agent/">https://lilianweng.github.io/posts/2023-06-23-agent/</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/agents/">Agents</a></li>
      <li><a href="http://localhost:1313/tags/llm/">LLM</a></li>
      <li><a href="http://localhost:1313/tags/transformers/">Transformers</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on x"
            href="https://x.com/intent/tweet/?text=Understanding%20LLM%20and%20AI%20Agents&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f&amp;hashtags=Agents%2cLLM%2ctransformers">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f&amp;title=Understanding%20LLM%20and%20AI%20Agents&amp;summary=Understanding%20LLM%20and%20AI%20Agents&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f&title=Understanding%20LLM%20and%20AI%20Agents">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on whatsapp"
            href="https://api.whatsapp.com/send?text=Understanding%20LLM%20and%20AI%20Agents%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on telegram"
            href="https://telegram.me/share/url?text=Understanding%20LLM%20and%20AI%20Agents&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Understanding LLM and AI Agents on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Understanding%20LLM%20and%20AI%20Agents&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fagentllm%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Kim&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
